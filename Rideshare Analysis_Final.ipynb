{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.enableHiveSupport().appName('Rideshare').getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = spark.sparkContext._conf.setAll([('spark.executor.memory', '4g'), ('spark.app.name', 'Spark Updated Conf'), ('spark.executor.cores', '4'), ('spark.cores.max', '4'), ('spark.driver.memory','4g')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.eventLog.enabled', 'true'),\n",
       " ('spark.yarn.jars',\n",
       "  'local:/opt/cloudera/parcels/CDH-6.3.0-1.cdh6.3.0.p0.1279813/lib/spark/jars/*,local:/opt/cloudera/parcels/CDH-6.3.0-1.cdh6.3.0.p0.1279813/lib/spark/hive/*'),\n",
       " ('spark.yarn.appMasterEnv.MKL_NUM_THREADS', '1'),\n",
       " ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES',\n",
       "  'http://md01.rcc.local:8088/proxy/application_1577383759214_11109,http://md02.rcc.local:8088/proxy/application_1577383759214_11109'),\n",
       " ('spark.sql.queryExecutionListeners',\n",
       "  'com.cloudera.spark.lineage.NavigatorQueryListener'),\n",
       " ('spark.lineage.log.dir', '/var/log/spark/lineage'),\n",
       " ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS',\n",
       "  'md01.rcc.local,md02.rcc.local'),\n",
       " ('spark.serializer', 'org.apache.spark.serializer.KryoSerializer'),\n",
       " ('spark.executorEnv.PYTHONPATH',\n",
       "  '/opt/cloudera/parcels/CDH/lib/spark/python/lib/py4j-0.10.7-src.zip:/opt/cloudera/parcels/CDH/lib/spark/python/lib/pyspark.zip<CPS>/opt/cloudera/parcels/CDH-6.3.0-1.cdh6.3.0.p0.1279813/lib/spark/python/lib/py4j-0.10.7-src.zip<CPS>/opt/cloudera/parcels/CDH-6.3.0-1.cdh6.3.0.p0.1279813/lib/spark/python/lib/pyspark.zip'),\n",
       " ('spark.yarn.historyServer.address', 'http://hd01.rcc.local:18088'),\n",
       " ('spark.driver.appUIAddress', 'http://md01.rcc.local:4056'),\n",
       " ('spark.ui.filters',\n",
       "  'org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter'),\n",
       " ('spark.network.crypto.enabled', 'false'),\n",
       " ('spark.executorEnv.MKL_NUM_THREADS', '1'),\n",
       " ('spark.executor.memory', '4g'),\n",
       " ('spark.ui.enabled', 'true'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.executor.extraLibraryPath',\n",
       "  '/opt/cloudera/parcels/CDH-6.3.0-1.cdh6.3.0.p0.1279813/lib/hadoop/lib/native'),\n",
       " ('spark.dynamicAllocation.schedulerBacklogTimeout', '1'),\n",
       " ('spark.yarn.config.gatewayPath', '/opt/cloudera/parcels'),\n",
       " ('spark.extraListeners', 'com.cloudera.spark.lineage.NavigatorAppListener'),\n",
       " ('spark.port.maxRetries', '60'),\n",
       " ('spark.sql.warehouse.dir', '/user/hive/warehouse'),\n",
       " ('spark.app.name', 'Spark Updated Conf'),\n",
       " ('spark.sql.catalogImplementation', 'hive'),\n",
       " ('spark.driver.log.persistToDfs.enabled', 'true'),\n",
       " ('spark.ui.proxyBase', '/proxy/application_1577383759214_11109'),\n",
       " ('spark.yarn.config.replacementPath', '{{HADOOP_COMMON_HOME}}/../../..'),\n",
       " ('spark.executorEnv.OPENBLAS_NUM_THREADS', '1'),\n",
       " ('spark.driver.extraLibraryPath',\n",
       "  '/opt/cloudera/parcels/CDH-6.3.0-1.cdh6.3.0.p0.1279813/lib/hadoop/lib/native'),\n",
       " ('spark.driver.memory', '4g'),\n",
       " ('spark.ui.killEnabled', 'true'),\n",
       " ('spark.driver.port', '35731'),\n",
       " ('spark.cores.max', '4'),\n",
       " ('spark.eventLog.dir', 'hdfs://nameservice1/user/spark/applicationHistory'),\n",
       " ('spark.dynamicAllocation.executorIdleTimeout', '60'),\n",
       " ('spark.executor.cores', '4'),\n",
       " ('spark.io.encryption.enabled', 'false'),\n",
       " ('spark.authenticate', 'false'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.RM_HA_URLS',\n",
       "  'md01.rcc.local:8088,md02.rcc.local:8088'),\n",
       " ('spark.shuffle.service.enabled', 'true'),\n",
       " ('spark.yarn.historyServer.allowTracking', 'true'),\n",
       " ('spark.yarn.appMasterEnv.OPENBLAS_NUM_THREADS', '1'),\n",
       " ('spark.shuffle.service.port', '7337'),\n",
       " ('spark.lineage.enabled', 'true'),\n",
       " ('spark.master', 'yarn'),\n",
       " ('spark.driver.host', 'md01.rcc.local'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.yarn.am.extraLibraryPath',\n",
       "  '/opt/cloudera/parcels/CDH-6.3.0-1.cdh6.3.0.p0.1279813/lib/hadoop/lib/native'),\n",
       " ('spark.dynamicAllocation.minExecutors', '0'),\n",
       " ('spark.yarn.isPython', 'true'),\n",
       " ('spark.dynamicAllocation.enabled', 'true'),\n",
       " ('spark.app.id', 'application_1577383759214_11109'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.driver.log.dfsDir', '/user/spark/driverLogs')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rideshares = spark.read.csv(\"/user/trasley/data/rideshare.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158617578"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rideshares.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Trip ID: string (nullable = true)\n",
      " |-- Trip Start Timestamp: string (nullable = true)\n",
      " |-- Trip End Timestamp: string (nullable = true)\n",
      " |-- Trip Seconds: integer (nullable = true)\n",
      " |-- Trip Miles: double (nullable = true)\n",
      " |-- Pickup Census Tract: long (nullable = true)\n",
      " |-- Dropoff Census Tract: long (nullable = true)\n",
      " |-- Pickup Community Area: integer (nullable = true)\n",
      " |-- Dropoff Community Area: integer (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Tip: integer (nullable = true)\n",
      " |-- Additional Charges: double (nullable = true)\n",
      " |-- Trip Total: double (nullable = true)\n",
      " |-- Shared Trip Authorized: boolean (nullable = true)\n",
      " |-- Trips Pooled: integer (nullable = true)\n",
      " |-- Pickup Centroid Latitude: double (nullable = true)\n",
      " |-- Pickup Centroid Longitude: double (nullable = true)\n",
      " |-- Pickup Centroid Location: string (nullable = true)\n",
      " |-- Dropoff Centroid Latitude: double (nullable = true)\n",
      " |-- Dropoff Centroid Longitude: double (nullable = true)\n",
      " |-- Dropoff Centroid Location: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rideshares.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+-------+-----+------------+-------------+----------------+-----------------+----+---+-----------+-----+-----------+------------+-------------------+--------------------+--------------------+--------------------+---------------------+--------------------+\n",
      "|             trip_id|          start_time|            end_time|seconds|miles|pickup_tract|dropoff_tract|pickup_comm_area|dropoff_comm_area|fare|tip|add_charges|total|shared_auth|trips_pooled|pickup_lat_centroid|pickup_long_centroid| pickup_loc_centroid|dropoff_lat_centroid|dropoff_long_centroid|dropoff_loc_centroid|\n",
      "+--------------------+--------------------+--------------------+-------+-----+------------+-------------+----------------+-----------------+----+---+-----------+-----+-----------+------------+-------------------+--------------------+--------------------+--------------------+---------------------+--------------------+\n",
      "|6e22fde8d26ed1363...|05/27/2019 11:30:...|05/27/2019 11:45:...|    728|  3.7|        null|         null|              24|                5| 7.5|  0|       2.55|10.05|      false|           1|      41.9012069941|      -87.6763559892|POINT (-87.676355...|       41.9477915865|       -87.6838349425|POINT (-87.683834...|\n",
      "|6e22fe44c471241c0...|06/11/2019 10:45:...|06/11/2019 11:15:...|   1706| 12.0| 17031842300|  17031411200|              24|               41|20.0|  0|       2.55|22.55|      false|           1|      41.8983058696|      -87.6536139825|POINT (-87.653613...|       41.7905666284|       -87.5940154442|POINT (-87.594015...|\n",
      "|6e22ffc00ed997604...|04/28/2019 11:15:...|04/28/2019 11:45:...|   2438| 23.9|        null|  17031980000|            null|               76|32.5|  0|       9.25|41.75|      false|           1|               null|                null|                null|       41.9790708201|       -87.9030396611|POINT (-87.903039...|\n",
      "|6e23001dc69639584...|04/18/2019 02:30:...|04/18/2019 03:15:...|   2569| 12.4| 17031081201|         null|               8|             null|25.0|  0|       2.55|27.55|      false|           1|      41.8991556134|      -87.6262105324|POINT (-87.626210...|                null|                 null|                null|\n",
      "|6e23008d0a34bd62c...|06/14/2019 06:30:...|06/14/2019 06:45:...|   1101|  7.0|        null|  17031283100|            null|               28|12.5|  0|       2.55|15.05|      false|           1|               null|                null|                null|       41.8692744531|       -87.6640472412|POINT (-87.664047...|\n",
      "|6e23011643a6dbfd3...|04/27/2019 05:45:...|04/27/2019 06:00:...|    824|  2.7| 17031841900|  17031081403|              28|                8| 7.5|  5|       2.55|15.05|      false|           1|      41.8679024175|      -87.6429586652|POINT (-87.642958...|       41.8909220259|       -87.6188683546|POINT (-87.618868...|\n",
      "|6e2301b77e5907a41...|04/11/2019 07:15:...|04/11/2019 07:30:...|    639|  2.0| 17031081403|  17031838300|               8|                8| 7.5|  0|       2.55|10.05|      false|           1|      41.8909220259|      -87.6188683546|POINT (-87.618868...|       41.9015669095|       -87.6384040116|POINT (-87.638404...|\n",
      "|6e23024d1a4de1249...|06/06/2019 04:00:...|06/06/2019 04:30:...|   1251|  3.0|        null|         null|               8|               28| 7.5|  0|        0.0|  7.5|       true|           3|       41.899602111|      -87.6333080367|POINT (-87.633308...|        41.874005383|       -87.6635175498|POINT (-87.663517...|\n",
      "|6e2302d66f77b705c...|04/18/2019 09:00:...|04/18/2019 09:30:...|   1840| 10.2| 17031040700|  17031839000|               4|               32|17.5|  0|       2.55|20.05|      false|           1|      41.9668063463|      -87.6940200973|POINT (-87.694020...|       41.8710158803|       -87.6314065252|POINT (-87.631406...|\n",
      "|6e2302e2a66c576f7...|06/13/2019 05:00:...|06/13/2019 05:15:...|    322|  0.5| 17031320100|  17031839100|              32|               32| 7.5|  3|       2.55|13.05|      false|           1|      41.8849871918|      -87.6209929134|POINT (-87.620992...|       41.8809944707|       -87.6327464887|POINT (-87.632746...|\n",
      "+--------------------+--------------------+--------------------+-------+-----+------------+-------------+----------------+-----------------+----+---+-----------+-----+-----------+------------+-------------------+--------------------+--------------------+--------------------+---------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rideshares = rideshares.withColumnRenamed(\"Trip ID\", \"trip_id\")\\\n",
    "    .withColumnRenamed(\"Trip Start Timestamp\",\"start_time\")\\\n",
    "    .withColumnRenamed(\"Trip End Timestamp\",\"end_time\")\\\n",
    "    .withColumnRenamed(\"Trip Seconds\",\"seconds\")\\\n",
    "    .withColumnRenamed(\"Trip Miles\",\"miles\")\\\n",
    "    .withColumnRenamed(\"Pickup Census Tract\",\"pickup_tract\")\\\n",
    "    .withColumnRenamed(\"Dropoff Census Tract\",\"dropoff_tract\")\\\n",
    "    .withColumnRenamed(\"Pickup Community Area\",\"pickup_comm_area\")\\\n",
    "    .withColumnRenamed(\"Dropoff Community Area\",\"dropoff_comm_area\")\\\n",
    "    .withColumnRenamed(\"Fare\",\"fare\")\\\n",
    "    .withColumnRenamed(\"Tip\",\"tip\")\\\n",
    "    .withColumnRenamed(\"Additional Charges\",\"add_charges\")\\\n",
    "    .withColumnRenamed(\"Trip Total\",\"total\")\\\n",
    "    .withColumnRenamed(\"Shared Trip Authorized\",\"shared_auth\")\\\n",
    "    .withColumnRenamed(\"Trips Pooled\",\"trips_pooled\")\\\n",
    "    .withColumnRenamed(\"Pickup Centroid Latitude\",\"pickup_lat_centroid\")\\\n",
    "    .withColumnRenamed(\"Pickup Centroid Longitude\",\"pickup_long_centroid\")\\\n",
    "    .withColumnRenamed(\"Pickup Centroid Location\",\"pickup_loc_centroid\")\\\n",
    "    .withColumnRenamed(\"Dropoff Centroid Latitude\",\"dropoff_lat_centroid\")\\\n",
    "    .withColumnRenamed(\"Dropoff Centroid Longitude\",\"dropoff_long_centroid\")\\\n",
    "    .withColumnRenamed(\"Dropoff Centroid Location\",\"dropoff_loc_centroid\")\n",
    "rideshares.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|start_time            |\n",
      "+----------------------+\n",
      "|05/27/2019 11:30:00 PM|\n",
      "|06/11/2019 10:45:00 PM|\n",
      "|04/28/2019 11:15:00 AM|\n",
      "|04/18/2019 02:30:00 PM|\n",
      "|06/14/2019 06:30:00 PM|\n",
      "|04/27/2019 05:45:00 PM|\n",
      "|04/11/2019 07:15:00 PM|\n",
      "|06/06/2019 04:00:00 PM|\n",
      "|04/18/2019 09:00:00 AM|\n",
      "|06/13/2019 05:00:00 PM|\n",
      "+----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rideshares.select(\"start_time\").show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|start_time         |\n",
      "+-------------------+\n",
      "|2019-05-27 11:30:00|\n",
      "|2019-06-11 10:45:00|\n",
      "|2019-04-28 11:15:00|\n",
      "|2019-04-18 02:30:00|\n",
      "|2019-06-14 06:30:00|\n",
      "|2019-04-27 05:45:00|\n",
      "|2019-04-11 07:15:00|\n",
      "|2019-06-06 04:00:00|\n",
      "|2019-04-18 09:00:00|\n",
      "|2019-06-13 05:00:00|\n",
      "+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StringType,IntegerType,DateType\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "\n",
    "rideshares = rideshares.withColumn('start_time',to_timestamp('start_time','MM/dd/yyyy HH:mm:ss')).withColumn('end_time',to_timestamp('end_time','MM/dd/yyyy HH:mm:ss'))\n",
    "rideshares.select('start_time').show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158503181"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Limit date range for consistency across datasets\n",
    "date_from='2018-11-01'\n",
    "date_to='2020-06-30'\n",
    "rideshares=rideshares.filter((rideshares.start_time>=date_from) & (rideshares.start_time<=date_to))\n",
    "rideshares.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+--------+-------+-----+------------+-------------+----------------+-----------------+----+---+-----------+-----+-----------+------------+-------------------+--------------------+-------------------+--------------------+---------------------+--------------------+\n",
      "|trip_id|start_time|end_time|seconds|miles|pickup_tract|dropoff_tract|pickup_comm_area|dropoff_comm_area|fare|tip|add_charges|total|shared_auth|trips_pooled|pickup_lat_centroid|pickup_long_centroid|pickup_loc_centroid|dropoff_lat_centroid|dropoff_long_centroid|dropoff_loc_centroid|\n",
      "+-------+----------+--------+-------+-----+------------+-------------+----------------+-----------------+----+---+-----------+-----+-----------+------------+-------------------+--------------------+-------------------+--------------------+---------------------+--------------------+\n",
      "|      0|         0|    8686| 214005| 5036|    48698479|     49360897|        10159824|         11389965| 142| 34|        131|  142|          0|           0|           10032980|            10032980|           10032980|            11265330|             11265330|            11265330|\n",
      "+-------+----------+--------+-------+-----+------------+-------------+----------------+-----------------+----+---+-----------+-----+-----------+------------+-------------------+--------------------+-------------------+--------------------+---------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, count, col\n",
    "\n",
    "#Show fields with null values\n",
    "rideshares.select([count(when(col(i).isNull(), i)).alias(i) for i in rideshares.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop rows where dropoff/pickup centroids are null - need them to accurately capture ride\n",
    "rideshares=rideshares.dropna(subset=['pickup_lat_centroid', 'pickup_long_centroid', 'dropoff_lat_centroid', 'dropoff_long_centroid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137237155"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rideshares.rdd.countApprox(timeout=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##rows that have multiple null values on start/end/length of time - can't calculate other values\n",
    "rideshares.where((col('start_time').isNull() & (col('end_time').isNull() | col('seconds').isNull()))).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rideshares.where(col('seconds').isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+\n",
      "|seconds|miles|hours|\n",
      "+-------+-----+-----+\n",
      "|   null|  3.4|    5|\n",
      "|   null|  1.1|    4|\n",
      "|   null|  1.7|    9|\n",
      "|   null|  2.2|    8|\n",
      "|   null|  2.1|    7|\n",
      "|   null|  5.4|    1|\n",
      "|   null|  3.8|    5|\n",
      "|   null|  1.8|    1|\n",
      "|   null|  2.1|   10|\n",
      "|   null|  3.4|    0|\n",
      "|   null| 13.0|    8|\n",
      "|   null|  1.5|    5|\n",
      "|   null|  2.9|    2|\n",
      "|   null|  9.5|    6|\n",
      "|   null|  4.5|    0|\n",
      "|   null|  1.7|    4|\n",
      "|   null| 10.5|    8|\n",
      "|   null|  1.8|    4|\n",
      "|   null|  3.3|    6|\n",
      "|   null|  4.4|    9|\n",
      "+-------+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import hour,minute,second\n",
    "\n",
    "rideshares.where(col('seconds').isNull()).withColumn(\"hours\",hour(\"end_time\")-hour(\"start_time\")).select(\"seconds\",\"miles\",\"hours\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like lots of cases where the ride was many hours yet only went a couple of miles - remove these records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137072012"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rideshares.filter(col('seconds').isNull() & (hour(col(\"end_time\"))-hour(col(\"start_time\"))>=1)).count()\n",
    "rideshares=rideshares.filter(~(col('seconds').isNull() & (hour(col(\"end_time\"))-hour(col(\"start_time\"))>=1)))\n",
    "rideshares.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+--------+-------+-----+------------+-------------+----------------+-----------------+----+---+-----------+-----+-----------+------------+-------------------+--------------------+-------------------+--------------------+---------------------+--------------------+\n",
      "|trip_id|start_time|end_time|seconds|miles|pickup_tract|dropoff_tract|pickup_comm_area|dropoff_comm_area|fare|tip|add_charges|total|shared_auth|trips_pooled|pickup_lat_centroid|pickup_long_centroid|pickup_loc_centroid|dropoff_lat_centroid|dropoff_long_centroid|dropoff_loc_centroid|\n",
      "+-------+----------+--------+-------+-----+------------+-------------+----------------+-----------------+----+---+-----------+-----+-----------+------------+-------------------+--------------------+-------------------+--------------------+---------------------+--------------------+\n",
      "|      0|         0|    6922|  16856| 4494|    34361760|     34361760|           99940|           104893| 109| 25|         99|  109|          0|           0|                  0|                   0|                  0|                   0|                    0|                   0|\n",
      "+-------+----------+--------+-------+-----+------------+-------------+----------------+-----------------+----+---+-----------+-----+-----------+------------+-------------------+--------------------+-------------------+--------------------+---------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rideshares.select([count(when(col(i).isNull(), i)).alias(i) for i in rideshares.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/@nikolasbielski/using-a-custom-udf-in-pyspark-to-compute-haversine-distances-d877b77b4b18\n",
    "#Compare miles feature to actual Euclidean distance\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "def get_distance(latit_a, longit_a, latit_b, longit_b):\n",
    "    # Transform to radians\n",
    "    longit_a, latit_a, longit_b, latit_b = map(radians, [longit_a,  latit_a, longit_b, latit_b])\n",
    "    dist_longit = longit_b - longit_a\n",
    "    dist_latit = latit_b - latit_a\n",
    "    # Calculate area\n",
    "    area = sin(dist_latit/2)**2 + cos(latit_a) * cos(latit_b) * sin(dist_longit/2)**2\n",
    "    # Calculate the central angle\n",
    "    central_angle = 2 * asin(sqrt(area))\n",
    "    radius = 6371\n",
    "    # Calculate Distance\n",
    "    distance = central_angle * radius\n",
    "    return abs(round(distance, 2))\n",
    "\n",
    "udf_get_distance = F.udf(get_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rideshares=rideshares.withColumn(\"distance\", udf_get_distance(rideshares.pickup_lat_centroid, rideshares.pickup_long_centroid, \\\n",
    "                        rideshares.dropoff_lat_centroid, rideshares.dropoff_long_centroid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+--------+-------+-----+------------+-------------+----------------+-----------------+----+---+-----------+-----+-----------+------------+-------------------+--------------------+-------------------+--------------------+---------------------+--------------------+--------+\n",
      "|trip_id|start_time|end_time|seconds|miles|pickup_tract|dropoff_tract|pickup_comm_area|dropoff_comm_area|fare|tip|add_charges|total|shared_auth|trips_pooled|pickup_lat_centroid|pickup_long_centroid|pickup_loc_centroid|dropoff_lat_centroid|dropoff_long_centroid|dropoff_loc_centroid|distance|\n",
      "+-------+----------+--------+-------+-----+------------+-------------+----------------+-----------------+----+---+-----------+-----+-----------+------------+-------------------+--------------------+-------------------+--------------------+---------------------+--------------------+--------+\n",
      "|      0|         0|    6922|  16856| 4494|    34361760|     34361760|           99940|           104893| 109| 25|         99|  109|          0|           0|                  0|                   0|                  0|                   0|                    0|                   0|       0|\n",
      "+-------+----------+--------+-------+-----+------------+-------------+----------------+-----------------+----+---+-----------+-----+-----------+------------+-------------------+--------------------+-------------------+--------------------+---------------------+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rideshares.select([count(when(col(i).isNull(), i)).alias(i) for i in rideshares.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rideshares=rideshares.dropna(subset=['seconds','end_time','miles','fare'])\n",
    "rideshares=rideshares.drop(*['pickup_tract','dropoff_tract'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+--------+-------+-----+----------------+-----------------+----+---+-----------+-----+-----------+------------+-------------------+--------------------+-------------------+--------------------+---------------------+--------------------+--------+\n",
      "|trip_id|start_time|end_time|seconds|miles|pickup_comm_area|dropoff_comm_area|fare|tip|add_charges|total|shared_auth|trips_pooled|pickup_lat_centroid|pickup_long_centroid|pickup_loc_centroid|dropoff_lat_centroid|dropoff_long_centroid|dropoff_loc_centroid|distance|\n",
      "+-------+----------+--------+-------+-----+----------------+-----------------+----+---+-----------+-----+-----------+------------+-------------------+--------------------+-------------------+--------------------+---------------------+--------------------+--------+\n",
      "|      0|         0|       0|      0|    0|           99914|           104872|   0|  0|          0|    0|          0|           0|                  0|                   0|                  0|                   0|                    0|                   0|       0|\n",
      "+-------+----------+--------+-------+-----+----------------+-----------------+----+---+-----------+-----+-----------+------------+-------------------+--------------------+-------------------+--------------------+---------------------+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rideshares.select([count(when(col(i).isNull(), i)).alias(i) for i in rideshares.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rideshares.where(col('end_time').isNull() & col('seconds').isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities = spark.read.csv(\"/user/trasley/data/chicago_communities.csv\", inferSchema=True, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('use trasley').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tracts=rideshares.crosstab('pickup_tract','dropoff_tract').toPandas()\n",
    "#tracts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = df.select(\"TYPE\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "codes = df.select(\"CODE\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "types_expr = [F.when(F.col(\"TYPE\") == ty, 1).otherwise(0).alias(\"e_TYPE_\" + ty) for ty in types]\n",
    "codes_expr = [F.when(F.col(\"CODE\") == code, 1).otherwise(0).alias(\"e_CODE_\" + code) for code in codes]\n",
    "df = df.select(\"ID\", \"TYPE\", \"CODE\", *types_expr+codes_expr)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoderEstimator\n",
    "\n",
    "#convert relevant categorical into one hot encoded\n",
    "indexer1 = StringIndexer(inputCol=\"pickup_comm_area\", outputCol=\"countryIdx\").setHandleInvalid(\"skip\")\n",
    "indexer2 = StringIndexer(inputCol=\"dropoff_comm_area\", outputCol=\"provinceIdx\").setHandleInvalid(\"skip\")\n",
    "indexer3 = StringIndexer(inputCol=\"variety\", outputCol=\"varietyIdx\").setHandleInvalid(\"skip\")\n",
    "indexer4 = StringIndexer(inputCol=\"winery\", outputCol=\"wineryIdx\").setHandleInvalid(\"skip\")\n",
    "\n",
    "#gather all indexers as inputs to the One Hot Encoder\n",
    "inputs = [indexer1.getOutputCol(), indexer2.getOutputCol(), \\\n",
    "          indexer3.getOutputCol(), indexer4.getOutputCol()]\n",
    "\n",
    "#create the one hot encoder\n",
    "encoder = OneHotEncoderEstimator(inputCols=inputs,  \\\n",
    "                                 outputCols=[\"countryVec\", \"provinceVec\", \\\n",
    "                                             \"varietyVec\", \"wineryVec\"])\n",
    "\n",
    "#run it through a pipeline\n",
    "pipeline = Pipeline(stages=[indexer1, indexer2, indexer3, indexer4, encoder])\n",
    "encodedData = pipeline.fit(df).transform(df)\n",
    "\n",
    "#we have removed NAs so dont need to impute missing values.\n",
    "#pipeline = pipeline.na.fill(0) \n",
    "\n",
    "encodedData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year, month, dayofmonth\n",
    "\n",
    "#Show monthly rides over time\n",
    "monthlyrides=rideshares.withColumn(\"year\",year(\"start_time\").cast(StringType())).withColumn(\"month\",month(\"start_time\").cast(StringType())).groupby(\"year\",\"month\").count().sort(['year','month'],ascending=False).toPandas()\n",
    "monthlyrides.plot(y=\"count\",figsize=(15,4), style=\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rideshares.select(\"pickup_comm_area\").distinct().show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities=communities.withColumnRenamed(\"_c0\",\"code\").withColumnRenamed(\"_c1\",\"community_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rideshares = rideshares.join(communities, rideshares.pickup_comm_area == communities.code, how='left_outer')\n",
    "rideshares.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drop blank community value codes\n",
    "rideshares=rideshares.dropna(subset=['code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poolAuth=rideshares.select(\"shared_auth\").groupby(\"shared_auth\").count().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poolAuth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poolAuth[\"shared_auth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(2)\n",
    "width = 0.35 \n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(x + width/2, poolAuth[\"count\"], width)\n",
    "\n",
    "ax.set_title('Individual vs Pooled Rides')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(poolAuth[\"shared_auth\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_riders=rideshares.where(rideshares.shared_auth==True).select(\"trips_pooled\").groupby(\"trips_pooled\").count().sort('count',ascending=False).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rideshares.where(rideshares.trips_pooled==4097).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_activity=rideshares.where(rideshares.dropoff_comm_area==22).withColumn(\"year\",year(\"start_time\")).withColumn(\"month\",month(\"start_time\")).groupby(\"year\",\"month\").count().sort(['year','month'],ascending=False).toPandas()\n",
    "community_activity.plot(y=\"count\",figsize=(15,4), style=\"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "distribution of:\n",
    "ride length\n",
    "cost\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
